{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA-4-S8-Praveen-Raghuvanshi-Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7zEUESo/iL0/b6uiXgB13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenraghuvanshi1512/EVA4/blob/Session-8/Session-8/Assignment-8/EVA_4_S8_Praveen_Raghuvanshi_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrQqN4zqMt5U",
        "colab_type": "text"
      },
      "source": [
        "## Steps Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcS9dBHZuJ0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Mount google drive\n",
        "# 2. Set the directory path of google drive\n",
        "# 3. Import all modules and libraries\n",
        "# 4. Set Device\n",
        "# 5. Import all the functions\n",
        "# 6. Load transformations\n",
        "# 7. Load dataset\n",
        "# 8. Load Classes\n",
        "# 9. Display sample images\n",
        "# 10. Load Resnet18 Model\n",
        "# 11. Define Loss function and optimizer\n",
        "# 12. Run train and test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOdHHdPxuQFs",
        "colab_type": "text"
      },
      "source": [
        "### 1. Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCII_8_auNbk",
        "colab_type": "code",
        "outputId": "54eb1f3e-3995-4dd0-ab7a-847d959b9a66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# Load data from Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iouz-VhCvRKa",
        "colab_type": "text"
      },
      "source": [
        "### 2. Set the directory path of google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYAhAXd7u8Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "sys.path.append('/content/drive/My Drive/eva-4/assignment-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EshyBNNlvXUB",
        "colab_type": "code",
        "outputId": "075c255a-847e-4a5a-d20e-00e9a28ba9b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd '/content/drive/My Drive/eva-4/assignment-8'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/eva-4/assignment-8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCrlbbXOvjzh",
        "colab_type": "code",
        "outputId": "441c134c-d559-4c30-ccfc-711ce383a189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcheckpoint\u001b[0m/  \u001b[01;34mdata\u001b[0m/  model.py  \u001b[01;34m__pycache__\u001b[0m/  S8_functions.py  utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_gBUHNhwZF8",
        "colab_type": "text"
      },
      "source": [
        "### 3. Import all modules and libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJfJaQkMwdcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UzFE61fvvzj",
        "colab_type": "text"
      },
      "source": [
        "### 4. Set Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdESvDmFvlO1",
        "colab_type": "code",
        "outputId": "2a5ce480-545d-47ec-a288-3045a0bbd3bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gXN5mwvw_mO",
        "colab_type": "text"
      },
      "source": [
        "###  5. Import all the functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yM0_rOMxCr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from S8_functions import myfunc, transformations, loadcifar10dataset, getclasses, display, train, test\n",
        "from model import Net, ResNet, resnet18"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgfbtDvV3Std",
        "colab_type": "text"
      },
      "source": [
        "###  6. Load Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOJImFEc3YO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train, transform_test = transformations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uso5HfFp3iQ5",
        "colab_type": "text"
      },
      "source": [
        "###  7. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNK1p6sk3oZX",
        "colab_type": "code",
        "outputId": "1eacf19d-bded-4845-c6dd-04b425cbc877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "trainset, trainloader, testset, testloader = loadcifar10dataset(transform_train, transform_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlrYDL2_xEiz",
        "colab_type": "text"
      },
      "source": [
        "###  8. Load Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LiQgSYO30gf",
        "colab_type": "code",
        "outputId": "8acaad27-e24c-4b3a-fbbc-48d049005f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classes = getclasses()\n",
        "print(classes)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUYcV4I137Wf",
        "colab_type": "text"
      },
      "source": [
        "### 9. Display sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBXRNlu14E0g",
        "colab_type": "code",
        "outputId": "c971ccfa-07e9-40f5-bc67-11643b975f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "display(4, trainloader, classes)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " ship  deer plane horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne3h4eKQo/Avcw8PDI0Xxv71/zY2fOYvXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUzQmcOr4Ui_",
        "colab_type": "text"
      },
      "source": [
        "### 10. Load Resnet18 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auPmRERP4d1J",
        "colab_type": "code",
        "outputId": "c23a5365-4cf5-4846-e17e-d4c1ade417c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Building Model\")\n",
        "net = resnet18()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ1XA3Vm6jDq",
        "colab_type": "code",
        "outputId": "1e4ccd29-c788-400b-a872-af78c6d31c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Display Model Summary\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "model = net.to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
            "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
            "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
            "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
            "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
            "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.25\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 53.89\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jddcsjNZ9mlq",
        "colab_type": "text"
      },
      "source": [
        "### 11. Define loss function and optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zZ539Vx9tcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD_6sHrs-DWj",
        "colab_type": "text"
      },
      "source": [
        "### 12. Run Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHGIiWEF-RMP",
        "colab_type": "code",
        "outputId": "5b0d3ec5-9cb7-4ffe-b082-4d25a4e032c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(30):\n",
        "    train(net, trainloader, device, optimizer, criterion, epoch)\n",
        "    test(net, testloader, device, criterion, epoch)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [================================================================>]  Step: 52ms | Tot: 10m48s | Train >> Loss: 1.573 | Acc: 43.288% (21644/50000) 12500/12500 \n",
            " [================================================================>]  Step: 21ms | Tot: 59s966ms | Test >> Loss: 1.146 | Acc: 60.500% (6050/10000) 2500/2500 \n",
            "\n",
            "Epoch: 1\n",
            " [================================================================>]  Step: 50ms | Tot: 10m43s | Train >> Loss: 1.003 | Acc: 64.644% (32322/50000) 12500/12500 \n",
            " [================================================================>]  Step: 27ms | Tot: 1m744ms | Test >> Loss: 0.791 | Acc: 72.120% (7212/10000) 2500/2500 \n",
            "\n",
            "Epoch: 2\n",
            " [================================================================>]  Step: 48ms | Tot: 10m43s | Train >> Loss: 0.780 | Acc: 72.986% (36493/50000) 12500/12500 \n",
            " [================================================================>]  Step: 23ms | Tot: 58s701ms | Test >> Loss: 0.689 | Acc: 76.170% (7617/10000) 2500/2500 \n",
            "\n",
            "Epoch: 3\n",
            " [================================================================>]  Step: 50ms | Tot: 10m41s | Train >> Loss: 0.658 | Acc: 77.382% (38691/50000) 12500/12500 \n",
            " [================================================================>]  Step: 19ms | Tot: 57s638ms | Test >> Loss: 0.569 | Acc: 80.710% (8071/10000) 2500/2500 \n",
            "\n",
            "Epoch: 4\n",
            " [================================================================>]  Step: 51ms | Tot: 10m40s | Train >> Loss: 0.579 | Acc: 80.060% (40030/50000) 12500/12500 \n",
            " [================================================================>]  Step: 20ms | Tot: 58s840ms | Test >> Loss: 0.513 | Acc: 82.900% (8290/10000) 2500/2500 \n",
            "\n",
            "Epoch: 5\n",
            " [================================================================>]  Step: 50ms | Tot: 10m47s | Train >> Loss: 0.517 | Acc: 82.128% (41064/50000) 12500/12500 \n",
            " [================================================================>]  Step: 22ms | Tot: 1m669ms | Test >> Loss: 0.501 | Acc: 83.080% (8308/10000) 2500/2500 \n",
            "\n",
            "Epoch: 6\n",
            " [================================================================>]  Step: 48ms | Tot: 10m46s | Train >> Loss: 0.470 | Acc: 83.652% (41826/50000) 12500/12500 \n",
            " [================================================================>]  Step: 24ms | Tot: 1m314ms | Test >> Loss: 0.465 | Acc: 84.380% (8438/10000) 2500/2500 \n",
            "\n",
            "Epoch: 7\n",
            " [================================================================>]  Step: 51ms | Tot: 10m46s | Train >> Loss: 0.429 | Acc: 85.306% (42653/50000) 12500/12500 \n",
            " [================================================================>]  Step: 29ms | Tot: 59s404ms | Test >> Loss: 0.440 | Acc: 85.320% (8532/10000) 2500/2500 \n",
            "\n",
            "Epoch: 8\n",
            " [================================================================>]  Step: 52ms | Tot: 10m47s | Train >> Loss: 0.398 | Acc: 86.496% (43248/50000) 12500/12500 \n",
            " [================================================================>]  Step: 20ms | Tot: 58s904ms | Test >> Loss: 0.419 | Acc: 85.920% (8592/10000) 2500/2500 \n",
            "\n",
            "Epoch: 9\n",
            " [================================================================>]  Step: 50ms | Tot: 10m46s | Train >> Loss: 0.370 | Acc: 87.090% (43545/50000) 12500/12500 \n",
            " [================================================================>]  Step: 22ms | Tot: 57s843ms | Test >> Loss: 0.412 | Acc: 86.230% (8623/10000) 2500/2500 \n",
            "\n",
            "Epoch: 10\n",
            " [================================================================>]  Step: 53ms | Tot: 10m44s | Train >> Loss: 0.344 | Acc: 88.238% (44119/50000) 12500/12500 \n",
            " [================================================================>]  Step: 20ms | Tot: 58s787ms | Test >> Loss: 0.435 | Acc: 85.770% (8577/10000) 2500/2500 \n",
            "\n",
            "Epoch: 11\n",
            " [================================================================>]  Step: 47ms | Tot: 10m46s | Train >> Loss: 0.323 | Acc: 88.856% (44428/50000) 12500/12500 \n",
            " [================================================================>]  Step: 21ms | Tot: 58s816ms | Test >> Loss: 0.389 | Acc: 87.370% (8737/10000) 2500/2500 \n",
            "\n",
            "Epoch: 12\n",
            " [================================================================>]  Step: 50ms | Tot: 10m40s | Train >> Loss: 0.300 | Acc: 89.536% (44768/50000) 12500/12500 \n",
            " [================================================================>]  Step: 24ms | Tot: 56s582ms | Test >> Loss: 0.394 | Acc: 86.680% (8668/10000) 2500/2500 \n",
            "\n",
            "Epoch: 13\n",
            " [================================================================>]  Step: 43ms | Tot: 10m42s | Train >> Loss: 0.283 | Acc: 90.152% (45076/50000) 12500/12500 \n",
            " [================================================================>]  Step: 20ms | Tot: 58s964ms | Test >> Loss: 0.397 | Acc: 86.930% (8693/10000) 2500/2500 \n",
            "\n",
            "Epoch: 14\n",
            " [================================================================>]  Step: 50ms | Tot: 10m43s | Train >> Loss: 0.263 | Acc: 90.850% (45425/50000) 12500/12500 \n",
            " [================================================================>]  Step: 22ms | Tot: 1m77ms | Test >> Loss: 0.324 | Acc: 89.380% (8938/10000) 2500/2500 \n",
            "\n",
            "Epoch: 15\n",
            " [================================================================>]  Step: 56ms | Tot: 10m45s | Train >> Loss: 0.250 | Acc: 91.286% (45643/50000) 12500/12500 \n",
            " [================================================================>]  Step: 24ms | Tot: 59s375ms | Test >> Loss: 0.358 | Acc: 88.140% (8814/10000) 2500/2500 \n",
            "\n",
            "Epoch: 16\n",
            " [================================================================>]  Step: 48ms | Tot: 10m49s | Train >> Loss: 0.237 | Acc: 91.794% (45897/50000) 12500/12500 \n",
            " [================================================================>]  Step: 20ms | Tot: 1m920ms | Test >> Loss: 0.323 | Acc: 88.990% (8899/10000) 2500/2500 \n",
            "\n",
            "Epoch: 17\n",
            " [================================================================>]  Step: 51ms | Tot: 10m44s | Train >> Loss: 0.224 | Acc: 92.196% (46098/50000) 12500/12500 \n",
            " [================================================================>]  Step: 19ms | Tot: 59s92ms | Test >> Loss: 0.320 | Acc: 89.500% (8950/10000) 2500/2500 \n",
            "\n",
            "Epoch: 18\n",
            " [================================================================>]  Step: 50ms | Tot: 10m45s | Train >> Loss: 0.211 | Acc: 92.644% (46322/50000) 12500/12500 \n",
            " [================================================================>]  Step: 21ms | Tot: 58s | Test >> Loss: 0.316 | Acc: 89.720% (8972/10000) 2500/2500 \n",
            "\n",
            "Epoch: 19\n",
            " [================================================================>]  Step: 51ms | Tot: 10m43s | Train >> Loss: 0.199 | Acc: 93.112% (46556/50000) 12500/12500 \n",
            " [================================================================>]  Step: 21ms | Tot: 58s548ms | Test >> Loss: 0.320 | Acc: 89.850% (8985/10000) 2500/2500 \n",
            "\n",
            "Epoch: 20\n",
            " [================================================================>]  Step: 49ms | Tot: 10m41s | Train >> Loss: 0.188 | Acc: 93.466% (46733/50000) 12500/12500 \n",
            " [================================================================>]  Step: 25ms | Tot: 59s857ms | Test >> Loss: 0.302 | Acc: 90.190% (9019/10000) 2500/2500 \n",
            "\n",
            "Epoch: 21\n",
            " [================================================================>]  Step: 51ms | Tot: 10m41s | Train >> Loss: 0.177 | Acc: 93.880% (46940/50000) 12500/12500 \n",
            " [================================================================>]  Step: 20ms | Tot: 59s145ms | Test >> Loss: 0.303 | Acc: 90.450% (9045/10000) 2500/2500 \n",
            "\n",
            "Epoch: 22\n",
            " [================================================================>]  Step: 50ms | Tot: 10m42s | Train >> Loss: 0.164 | Acc: 94.298% (47149/50000) 12500/12500 \n",
            " [================================================================>]  Step: 20ms | Tot: 59s376ms | Test >> Loss: 0.301 | Acc: 90.710% (9071/10000) 2500/2500 \n",
            "\n",
            "Epoch: 23\n",
            " [================================================================>]  Step: 50ms | Tot: 10m41s | Train >> Loss: 0.161 | Acc: 94.276% (47138/50000) 12500/12500 \n",
            " [================================================================>]  Step: 23ms | Tot: 57s858ms | Test >> Loss: 0.339 | Acc: 89.810% (8981/10000) 2500/2500 \n",
            "\n",
            "Epoch: 24\n",
            " [================================================================>]  Step: 50ms | Tot: 10m39s | Train >> Loss: 0.154 | Acc: 94.572% (47286/50000) 12500/12500 \n",
            " [================================================================>]  Step: 19ms | Tot: 57s930ms | Test >> Loss: 0.300 | Acc: 90.500% (9050/10000) 2500/2500 \n",
            "\n",
            "Epoch: 25\n",
            " [================================================================>]  Step: 52ms | Tot: 10m40s | Train >> Loss: 0.144 | Acc: 94.982% (47491/50000) 12500/12500 \n",
            " [================================================================>]  Step: 22ms | Tot: 1m531ms | Test >> Loss: 0.314 | Acc: 90.460% (9046/10000) 2500/2500 \n",
            "\n",
            "Epoch: 26\n",
            " [================================================================>]  Step: 50ms | Tot: 10m42s | Train >> Loss: 0.137 | Acc: 95.192% (47596/50000) 12500/12500 \n",
            " [================================================================>]  Step: 18ms | Tot: 57s380ms | Test >> Loss: 0.310 | Acc: 90.720% (9072/10000) 2500/2500 \n",
            "\n",
            "Epoch: 27\n",
            " [================================================================>]  Step: 51ms | Tot: 10m41s | Train >> Loss: 0.129 | Acc: 95.410% (47705/50000) 12500/12500 \n",
            " [================================================================>]  Step: 25ms | Tot: 58s971ms | Test >> Loss: 0.316 | Acc: 90.310% (9031/10000) 2500/2500 \n",
            "\n",
            "Epoch: 28\n",
            " [================================================================>]  Step: 58ms | Tot: 10m41s | Train >> Loss: 0.122 | Acc: 95.676% (47838/50000) 12500/12500 \n",
            " [================================================================>]  Step: 18ms | Tot: 57s66ms | Test >> Loss: 0.317 | Acc: 90.700% (9070/10000) 2500/2500 \n",
            "\n",
            "Epoch: 29\n",
            " [================================================================>]  Step: 45ms | Tot: 10m39s | Train >> Loss: 0.119 | Acc: 95.856% (47928/50000) 12500/12500 \n",
            " [================================================================>]  Step: 21ms | Tot: 58s597ms | Test >> Loss: 0.297 | Acc: 91.110% (9111/10000) 2500/2500 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmvSUlfTa1j9",
        "colab_type": "text"
      },
      "source": [
        "### 13. Analysis\n",
        "- No of Epochs : 30\n",
        "- Best Train Acc: 95.856%\n",
        "- Best Test  Acc: 91.110%\n",
        "- No Model changes in Resnet18\n",
        "- Extra things done\n",
        "  - Normalization: \n",
        "    - transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "  - Image augmentation\n",
        "    - Train\n",
        "      - RandomCrop\n",
        "      - RandomHorizontalFlip\n",
        "    - Test\n",
        "      - Nothing\n",
        "- Overfitting \n",
        "  - Calculation: (100 - 91.110) + 95.856 = 104.746 --> No overfitting\n",
        "  - Difference : 95.856 - 91.110 = 4.746 --> Less -> No overfitting\n",
        "- Train and test acc were converging till epoch 7 and started to diverge post that.\n",
        "- There has been a continous increase in train accuracy\n",
        "- Test accuracy is fluctuating\n",
        "- Gap between train and test acc is 4.7 in last epoch which is reasonable\n",
        "- The model has capacity to be trained further but accuracy gains won't be too much."
      ]
    }
  ]
}